#数据清洗

数据清洗是数据挖掘中一项重要的工作，好的数据挖掘需要干净的数据支撑。可以说没有高质量的数据，就没有高质量的数据挖掘。

##数据质量的原则

简要概括: 完全合一

- 完整性: 单条数据是否存在空值，统计字段是否完全

- 全面性: 观察一列的数据是否全面，如数据单位、数据定义、数据本身

- 合法性: 数据是否符合现实。比如一个人的年龄超过500岁，显然不合常理

- 唯一性: 数据是否存在重复记录，是否单列只记录了一个参数。


####完整性

1、缺失值

- 删除:删除缺失值的记录

- 均值:使用当前列的均值

- 高频:使用当前列出现频率最高的数据

2、空行

- 删除


####全面性

1、列数据的不统一

- 统一单位


####合理性

1、非ASCII字符

- 删除或替换

####唯一性

1、一列有多个参数

- 分开

2、重复数据

- 删除

####常用操作
字符串类型数字化:
```python
data[u'攻击范围'] = data[u'攻击范围'].map({'远程' : 1 , '近战' : 0})
```

#数据集成

####定义
数据集成是将多个数据源合并存放在一个数据存储中，从而方便后续的数据挖掘工作。数据集成是数据挖掘的前奏。

####数据集成的两种架构

1、 ETL
- ETL 是英文 Extract、Transform 和 Load 的缩写，顾名思义它包括了数据抽取、转换、加载三个过程。

- ETL 的过程为提取 (Extract)——转换 (Transform)——加载 (Load)，在数据源抽取后首先进行转换，然后将转换的结果写入目的地

2、ELT

- ETL 的过程为提取 (Extract)——转换 (Transform)——加载 (Load)，在数据源抽取后首先进行转换，然后将转换的结果写入目的地


####ETL常用工具

典型的 ETL 工具有:
- 商业软件：Informatica PowerCenter、IBM InfoSphere DataStage、Oracle Data Integrator、Microsoft SQL Server Integration Services 等

- 开源软件：Kettle、Talend、Apatar、Scriptella、DataX、Sqoop 等





#数据变换

####定义
- 在数据变换前，我们需要先对字段进行筛选，然后对数据进行探索和相关性分析，接着是选择算法模型（这里暂时不需要进行模型计算），然后针对算法模型对数据的需求进行数据变换，从而完成数据挖掘前的准备工作。

####常见的变换方法

- 数据平滑：去除数据中的噪声，将连续数据离散化。这里可以采用分箱、聚类和回归的方式进行数据平滑；

- 数据聚集：对数据进行汇总，在 SQL 中有一些聚集函数可以供我们操作，比如 Max() 反馈某个字段的数值最大值，Sum() 返回某个字段的数值总和；

- 数据概化：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国；

- 数据规范化：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中。常用的方法有最小—最大规范化、Z—score 规范化、按小数定标规范化等

- 属性构造：构造出新的属性并添加到属性集中。这里会用到特征工程的知识，因为通过属性与属性的连接构造新的属性，其实就是特征工程。比如说，数据表中统计每个人的英语、语文和数学成绩，你可以构造一个“总和”这个属性，来作为新属性。这样“总和”这个属性就可以用到后续的数据挖掘计算中。
